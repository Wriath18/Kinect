{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_med7_trf\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3417557009.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    image_path = #here will be fetch function\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def detection():\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    image_path = #here will be fetch function\n",
    "    final_image = image_processing(image_path=image_path)\n",
    "    result = reader.readtext(final_image)\n",
    "    txt = []\n",
    "    for detection in result:\n",
    "        # print(detection[1])\n",
    "        txt.append(detection[1])\n",
    "\n",
    "    return \" \".join(txt)\n",
    "\n",
    "\n",
    "def image_processing(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    reizised_img = img[200:1500, :]\n",
    "    return reizised_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Return None if frequency not found\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[43mmed7_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mmed7_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ments\u001b[39m\u001b[38;5;124m'\u001b[39m: med7\u001b[38;5;241m.\u001b[39mpipe_labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolors\u001b[39m\u001b[38;5;124m'\u001b[39m: col_dict}\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Text containing medical concepts\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mdetection\u001b[49m()  \u001b[38;5;66;03m# Replace with your detection function\u001b[39;00m\n\u001b[0;32m     15\u001b[0m doc \u001b[38;5;241m=\u001b[39m med7(text)\n\u001b[0;32m     17\u001b[0m drug_data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detection' is not defined"
     ]
    }
   ],
   "source": [
    "def med7_model():\n",
    "  global medication_names\n",
    "  medication_names = []\n",
    "  med7 = en_core_med7_trf.load()\n",
    "  col_dict = {}\n",
    "  seven_colours = ['#e6194B', '#3cb44b', '#ffe119', '#ffd8b1', '#f58231', '#f032e6', '#42d4f4']\n",
    "  for label, color in zip(med7.pipe_labels['ner'], seven_colours):\n",
    "    col_dict[label] = color\n",
    "\n",
    "  options = {'ents': med7.pipe_labels['ner'], 'colors': col_dict}\n",
    "\n",
    "  # Text containing medical concepts\n",
    "  text = detection()  # Replace with your detection function\n",
    "\n",
    "  doc = med7(text)\n",
    "\n",
    "  drug_data = []\n",
    "  for ent in doc.ents:\n",
    "    if ent.label_ == \"DRUG\":\n",
    "      medication_names.append(ent.text)\n",
    "      drug_data.append([ent.text, extract_frequency(ent.text, text)])  # Add frequency\n",
    "\n",
    "  # Write drug data to CSV file\n",
    "  with open(\"drug_info_.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Drug Name\", \"Frequency\"])\n",
    "    writer.writerows(drug_data)\n",
    "\n",
    "  spacy.displacy.render(doc, style='ent', jupyter=True, options=options)\n",
    "\n",
    "def extract_frequency(drug_name, text):\n",
    "  # Implement your logic to extract frequency from the text based on drug_name\n",
    "  # This example provides a basic placeholder, replace with your actual implementation\n",
    "  frequency_pattern = re.compile(f\"{re.escape(drug_name)} \\((.*?)\\)\")\n",
    "  # Example pattern for finding frequency near drug_name\n",
    "  match = re.search(frequency_pattern, text)\n",
    "  if match:\n",
    "    return match.group(1)  # Extract the matched frequency\n",
    "  else:\n",
    "    return None  # Return None if frequency not found\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assiatant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import google.generativeai as genai\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    voice_id = 1\n",
    "    engine = pyttsx3.init()\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[voice_id].id)\n",
    "    engine.setProperty('rate', 190) \n",
    "    engine.setProperty('volume', 0.9)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model_name = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    "retriever_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(retriever_model_name)\n",
    "retriever_model = DPRContextEncoder.from_pretrained(retriever_model_name)\n",
    "\n",
    "generator_model_name = \"microsoft/DialoGPT-medium\"\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(generator_model_name)\n",
    "generator_model = AutoModelForCausalLM.from_pretrained(generator_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    voice_id = 1\n",
    "    engine = pyttsx3.init()\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[voice_id].id)\n",
    "    engine.setProperty('rate', 190) \n",
    "    engine.setProperty('volume', 0.9)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model_name = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    "retriever_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(retriever_model_name)\n",
    "retriever_model = DPRContextEncoder.from_pretrained(retriever_model_name)\n",
    "\n",
    "generator_model_name = \"microsoft/DialoGPT-medium\"\n",
    "generator_tokenizer = AutoTokenizer.from_pretrained(generator_model_name)\n",
    "generator_model = AutoModelForCausalLM.from_pretrained(generator_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_about_drug(user_question):\n",
    "    drug_info = {}\n",
    "    with open(\"drug_info.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            drug_name, drug_frequency = row\n",
    "            drug_info[drug_name.lower()] = drug_frequency\n",
    "\n",
    "    print(drug_info) # check 1\n",
    "    # user_question = \"How many times do i have to take salbair ?\"\n",
    "\n",
    "    query_tokens = user_question.lower().split()\n",
    "    print(query_tokens)\n",
    "    drug_name = None\n",
    "    for token in query_tokens:\n",
    "        if token in drug_info:\n",
    "            drug_name = token\n",
    "            break\n",
    "    if drug_name:\n",
    "        passage = f\"{drug_name.capitalize()} is taken {drug_info[drug_name]}\"\n",
    "    else:\n",
    "        try:\n",
    "            genai.configure(api_key='AIzaSyDlyEdausw88tQwGC7BOnF4AtmgfMOvsoA')  # Replace with your API key\n",
    "            model = genai.GenerativeModel('gemini-pro')\n",
    "            response = model.generate_content(user_question)\n",
    "            passage = response.text\n",
    "        except Exception as e:\n",
    "            passage = f\"Error accessing Gemini API: {e}\"\n",
    "\n",
    "    input_ids = generator_tokenizer.encode(user_question + \" \" + passage, return_tensors=\"pt\")\n",
    "    output = generator_model.generate(input_ids, max_new_tokens=100, num_return_sequences=1, pad_token_id=generator_tokenizer.eos_token_id)\n",
    "    response = generator_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Response:\", response)\n",
    "    speak(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from fuzzywuzzy import process\n",
    "import pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_speech():\n",
    "    while True:\n",
    "        print(f\"\\nListening .....\")\n",
    "        sp = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            sp.pause_threshold = 0.5\n",
    "            sp.energy_threshold = 3500\n",
    "            audio = sp.listen(source)\n",
    "            txt = sp.recognize_google(audio, language=\"en-in\")\n",
    "            print(f\"User says {txt}\")\n",
    "            new_txt = autocorrect_medication(txt)\n",
    "            print(new_txt)\n",
    "            ask_about_drug(new_txt)\n",
    "            print(\"Stoppped\")\n",
    "            return txt\n",
    "        \n",
    "\n",
    "\n",
    "def autocorrect_medication(input_text):\n",
    "    # Split input into individual words\n",
    "    words = input_text.split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        closest_match = process.extractOne(word, medication_names)\n",
    "        if closest_match is not None:\n",
    "            matched_word, similarity = closest_match\n",
    "            if similarity >= 75:  \n",
    "                corrected_words.append(matched_word)\n",
    "            else:\n",
    "                corrected_words.append(word)  \n",
    "        else:\n",
    "            corrected_words.append(word) \n",
    "    return ' '.join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_image(url, file_path):\n",
    "    try:\n",
    "        # Fetch the image content\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Save the image to the local file\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(\"Image downloaded successfully.\")\n",
    "        else:\n",
    "            print(\"Failed to download image. Status code:\", response.status_code)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# URL of the image to download\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Local file name where you want to save the image (you can change the file extension if needed)\n",
    "# local_file_name = \"image.jpg\"\n",
    "\n",
    "# # Combine current directory and file name to get the full file path\n",
    "# local_file_path = os.path.join(current_directory, local_file_name)\n",
    "\n",
    "# # Download the image\n",
    "# download_image(download_url, local_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded successfully.\n",
      "Download URL: https://firebasestorage.googleapis.com/v0/b/seva-auth-739b8.appspot.com/o/1710500763192prescription.jpeg?alt=media&token=a5df5a0f-c059-4fa6-a238-d6885e3cce09\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from bson import ObjectId # Importing ObjectId\n",
    "\n",
    "def fetch():\n",
    "    # Connect to MongoDB\n",
    "    client = pymongo.MongoClient(\"mongodb+srv://sanchitbhalla15:YjVo112Ii05IatAq@cluster0.otghuex.mongodb.net/seva-auth?retryWrites=true&w=majority\")\n",
    "    db = client[\"seva-auth\"]  # Replace \"your-database\" with the name of your MongoDB database\n",
    "    collection = db[\"users\"]  # Replace \"your-collection\" with the name of your MongoDB collection\n",
    "\n",
    "    # Fetch the document containing the URL\n",
    "    result = collection.find_one({\"_id\": ObjectId(\"65f42879d4b7fa7a909cf33a\")})  # Replace \"your-image-id\" with the ID of the image document\n",
    "\n",
    "    if result:\n",
    "        download_url = result[\"currentPrescription\"]\n",
    "        current_directory = os.getcwd()\n",
    "\n",
    "        # Local file name where you want to save the image (you can change the file extension if needed)\n",
    "        local_file_name = \"image.jpg\"\n",
    "\n",
    "        # Combine current directory and file name to get the full file path\n",
    "        local_file_path = os.path.join(current_directory, local_file_name)\n",
    "        download_image(download_url, local_file_path)\n",
    "        print(\"Download URL:\", download_url)\n",
    "    else:\n",
    "        print(\"Document not found\")\n",
    "\n",
    "fetch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
